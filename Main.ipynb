{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сервис для статистического анализа потока посетителей.\n",
    "## Пол, возраст и интенсивность посещений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/why/Documents/github/Hack_university/models.py:248: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=16, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  bias=self._use_bias)(inputs)\n",
      "/Users/why/Documents/github/Hack_university/models.py:196: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  bias=self._use_bias)(convs)\n",
      "/Users/why/Documents/github/Hack_university/models.py:207: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  bias=self._use_bias)(convs)\n",
      "/Users/why/Documents/github/Hack_university/models.py:215: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  bias=self._use_bias)(net)\n",
      "/Users/why/Documents/github/Hack_university/models.py:219: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return merge([convs, shortcut], mode=\"sum\")\n",
      "/usr/local/lib/python3.6/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/Users/why/Documents/github/Hack_university/models.py:196: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  bias=self._use_bias)(convs)\n",
      "/Users/why/Documents/github/Hack_university/models.py:207: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  bias=self._use_bias)(convs)\n",
      "/Users/why/Documents/github/Hack_university/models.py:215: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), strides=(2, 2), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  bias=self._use_bias)(net)\n",
      "/Users/why/Documents/github/Hack_university/models.py:196: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  bias=self._use_bias)(convs)\n",
      "/Users/why/Documents/github/Hack_university/models.py:196: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  bias=self._use_bias)(convs)\n",
      "/Users/why/Documents/github/Hack_university/models.py:207: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  bias=self._use_bias)(convs)\n",
      "/Users/why/Documents/github/Hack_university/models.py:215: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), strides=(2, 2), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  bias=self._use_bias)(net)\n",
      "/Users/why/Documents/github/Hack_university/models.py:196: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  bias=self._use_bias)(convs)\n",
      "/Users/why/Documents/github/Hack_university/models.py:258: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D(pool_size=(8, 8), strides=(1, 1), padding=\"same\")`\n",
      "  pool = AveragePooling2D(pool_size=(8, 8), strides=(1, 1), border_mode=\"same\")(relu)\n",
      "/Users/why/Documents/github/Hack_university/models.py:261: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=2, kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  W_regularizer=l2(self._weight_decay), activation=\"softmax\")(flatten)\n",
      "/Users/why/Documents/github/Hack_university/models.py:263: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=101, kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  W_regularizer=l2(self._weight_decay), activation=\"softmax\")(flatten)\n",
      "/Users/why/Documents/github/Hack_university/models.py:265: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n",
      "  model = Model(input=inputs, output=[predictions_g, predictions_a])\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "fdet = models.FaceDetection()\n",
    "fdes = models.FaceDescription('data/model_weights/LandmarkFace.dat', 'data/model_weights/ResNetFace.dat')\n",
    "\n",
    "AGS_model = models.WideResNetCreater()()\n",
    "img_size = 64\n",
    "\n",
    "AGS_model.load_weights(os.path.join(\"data/model_weights/\", \"weights.18-4.06.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               font_scale=1, thickness=2):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.rectangle(image, (x, y - size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нахождение и распознавание лиц.\n",
    "## Благодоря технологиям верифекации человека по лицу наш сервис всегда знает, кто когда зашел и ушел, а так же сколько человек сейчас находится в помещении.\n",
    "### Пример \"Face Detection\".\n",
    "<img src=\"data/images/facedetect.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'data/test.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(source)\n",
    "\n",
    "facesV = []\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    for i in range(10):\n",
    "        cap.read()\n",
    "    \n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    try:\n",
    "        img = cv2.resize(img, (480 * 2,270 * 2))\n",
    "        img_h, img_w, img_ch = np.shape(img)\n",
    "    except:\n",
    "        break\n",
    "\n",
    "    dets = fdet(img)\n",
    "\n",
    "    facesV = fdes(img, dets = dets)\n",
    "\n",
    "    input_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faces = np.empty((len(dets), img_size, img_size, 3))\n",
    "\n",
    "    if len(dets) > 0:\n",
    "\n",
    "        for i, d in enumerate(dets):\n",
    "            x1, y1, x2, y2, w, h = d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height()\n",
    "            xw1 = max(int(x1 - 0.4 * w), 0)\n",
    "            yw1 = max(int(y1 - 0.4 * h), 0)\n",
    "            xw2 = min(int(x2 + 0.4 * w), img_w - 1)\n",
    "            yw2 = min(int(y2 + 0.4 * h), img_h - 1)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "            faces[i,:,:,:] = cv2.resize(img[yw1:yw2 + 1, xw1:xw2 + 1, :], (img_size, img_size))\n",
    "\n",
    "\n",
    "        results = AGS_model.predict(faces)\n",
    "        predicted_genders = results[0]\n",
    "        ages = np.arange(0, 101).reshape(101, 1)\n",
    "        predicted_ages = results[1].dot(ages).flatten()\n",
    "\n",
    "\n",
    "        ages_label = ['C' for i in range(len(dets))]\n",
    "\n",
    "        for i, d in enumerate(dets):\n",
    "\n",
    "            if predicted_ages[i] < 18:\n",
    "                ages_label[i] = 'C'\n",
    "\n",
    "            elif 18 <= predicted_ages[i] < 30:\n",
    "                ages_label[i] = 'Y'\n",
    "\n",
    "            elif 30 <= predicted_ages[i] < 55:\n",
    "                ages_label[i] = 'A'\n",
    "\n",
    "            else:\n",
    "                ages_label[i] = 'O'\n",
    "\n",
    "            label = \"{}{}\".format(ages_label[i],\"F\" if predicted_genders[i][0] > 0.5 else \"M\")\n",
    "            draw_label(img, (d.left(), d.top()), label)\n",
    "\n",
    "        \n",
    "    cv2.imshow('capture', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание лиц 128-мерным вектором.\n",
    "## После нахождения лиц на изображении нейронная сеть типа ResNet-34 раскладывает его на 128-мерный вектор. После мы можем их сравнивать на схожесть. \n",
    "\n",
    "### Пример \"Face Description\".\n",
    "<img src=\"data/images/facesPlot.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize = (20,10), dpi = 400)\n",
    "\n",
    "# for i,face in enumerate(facesV):\n",
    "#     plt.plot(face + i, label = 'Face_' + str(i))\n",
    "# plt.legend()\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, SVG\n",
    "\n",
    "fig = SVG(models.visModel(AGS_model, savePath = 'data/images/', name = 'AGS_structure'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация по полу и оценка возраста\n",
    "## Для классификации пола и  оценки возраста также используется сеть типа ResNet, но в этот раз мы имеем два выхода, один бинарный, он говорит мужчина перед нами или женщина, а второй выдает вектор, сумма координат которого даст оценку возраста.\n",
    "### Структура модели.\n",
    "<img src=\"data/images/AGS_structure.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRAM = models.IntensRecModelCreater(input_dim = 2, power = 128)()\n",
    "fig = SVG(models.visModel(IRAM, savePath = 'data/images/', name = 'IRAM_structure'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Для анализа временных последовательностей мы используем рекуррентные нейронные сети\n",
    "## Они позволяют нам предсказывать следующие во времени события\n",
    "### Пример рекуррентной сети\n",
    "\n",
    "<img src=\"data/images/IRAM_structure.png\" width=\"30%\">\n",
    "\n",
    "\n",
    "# Мы сгенерировали синтетическую выборку с посещаемостью \n",
    "## Она содержит ровно 1 год, где каждый объект - это 1 час и метка дня недели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import dataGenerator as gen\n",
    "\n",
    "data_set, weekTest = gen.generate()\n",
    "\n",
    "plt.figure(figsize = (6,3), dpi = 250)\n",
    "plt.plot([d[0] for d in data_set[:24*7]], label = 'trainWeek')\n",
    "plt.plot([d[0] for d in weekTest], label = 'testWeek')\n",
    "plt.legend()\n",
    "plt.yticks()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, Y = models.pad_sequences(data_set)\n",
    "\n",
    "Y = [d[0] for d in Y]\n",
    "\n",
    "#history = models.fitModel(IRAM, X , Y, 'data/model_weights/RNN_Analys1', \n",
    "#                          val_rate = 0.1, epochs = 1000, batch_size = 128)\n",
    "\n",
    "IRAM = models._load_model('data/model_weights/RNN_Analys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YP = IRAM.predict(X)\n",
    "\n",
    "plt.figure(figsize = (6,3), dpi = 250)\n",
    "\n",
    "plt.plot(YP[:24*7], label = \"predicted\")\n",
    "plt.plot(Y[:24*7], label = \"target\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = models.pad_sequences(weekTest)\n",
    "\n",
    "Y = [d[0] for d in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "_x = weekTest[:24]\n",
    "YP = []\n",
    "for i in range(len(weekTest) - 24):\n",
    "    p = IRAM.predict(np.array([_x]))\n",
    "    _x = _x[1:]\n",
    "    _x.append([float(p),weekTest[24 + i][1]])\n",
    "    YP.append(float(p))\n",
    "\n",
    "plt.figure(figsize = (6,3), dpi = 250)\n",
    "\n",
    "plt.plot(YP, label = \"predicted\")\n",
    "#plt.plot(Y, label = \"target\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum((np.array(YP) - np.array(Y))**2) / len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "\n",
    "data_set, weekTest = gen.generate()\n",
    "\n",
    "ANIMMODEL = models.IntensRecModelCreater(input_dim = 2, power = 128)()\n",
    "\n",
    "batch_size = 128\n",
    "frames = 100\n",
    "Epoch = 0\n",
    "\n",
    "X, Y = models.pad_sequences(data_set)\n",
    "\n",
    "_, YT = models.pad_sequences(weekTest)\n",
    "\n",
    "Y = [d[0] for d in Y]\n",
    "YT = [d[0] for d in YT]\n",
    "\n",
    "plotcols = [\"g\",\"b\"]\n",
    "labels = [\"Target\", \"Predicted\"]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = plt.axes(xlim=(0, 24*7), ylim=(0,1.1))\n",
    "line, = ax1.plot([], [], lw=2)\n",
    "\n",
    "lines = []\n",
    "for index in range(2):\n",
    "    lobj = ax1.plot([],[],lw=2,color=plotcols[index], label = labels[index])[0]\n",
    "    lines.append(lobj)\n",
    "\n",
    "    \n",
    "def init():\n",
    "    for line in lines:\n",
    "        line.set_data([],[])\n",
    "    return lines\n",
    "\n",
    "def animate(i):\n",
    "    \n",
    "    global ANIMMODEL\n",
    "    global X\n",
    "    global Y\n",
    "    global YT\n",
    "    global weekTest\n",
    "    global Epoch\n",
    "    global batch_size\n",
    "\n",
    "    Epoch += 1\n",
    "    \n",
    "    X,Y = models._shuffle(X,Y)\n",
    "    \n",
    "    print(str(i) + ' Epoch')\n",
    "    _ = models.fitModel(ANIMMODEL, X , Y, 'data/model_weights/RNN_Analys1', \n",
    "                          val_rate = 0.1, epochs = 1, batch_size = 128)\n",
    "    \n",
    "    _x = weekTest[:24]\n",
    "    YP = []\n",
    "    for i in range(len(weekTest) - 24):\n",
    "        p = ANIMMODEL.predict(np.array([_x]))\n",
    "        _x = _x[1:]\n",
    "        _x.append([float(p),weekTest[24 + i][1]])\n",
    "        YP.append(float(p))\n",
    "\n",
    "    ylist = [YT,YP]\n",
    "    xlist = [[j for j in range(len(YT))],[j for j in range(len(YT))]]\n",
    "\n",
    "    for lnum,line in enumerate(lines):\n",
    "        line.set_data(xlist[lnum],ylist[lnum])\n",
    "\n",
    "        \n",
    "    plt.title(\"Epoch: \" + str(Epoch))\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    return lines\n",
    "\n",
    "#anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "#                               frames=frames, blit=True)\n",
    "\n",
    "#Writer = animation.writers['ffmpeg']\n",
    "#writer = Writer(fps=10, metadata=dict(artist='Me'), bitrate=1800)\n",
    "\n",
    "#anim.save('learn.mp4', writer=writer)\n",
    "\n",
    "#anim.save('learn.mp4', fps=10, extra_args=['-vcodec', 'libx264'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
